{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import all the necessary packages.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from matplotlib import gridspec\n",
    "from scipy.sparse import hstack\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>medium_image_url</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>title</th>\n",
       "      <th>formatted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004GSI2OS</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>Onyx Black/ Stone</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>featherlite ladies long sleeve stain resistant...</td>\n",
       "      <td>$26.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B012YX2ZPI</td>\n",
       "      <td>HX-Kingdom Fashion T-shirts</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>womens unique 100 cotton  special olympics wor...</td>\n",
       "      <td>$9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B003BSRPB0</td>\n",
       "      <td>FeatherLite</td>\n",
       "      <td>White</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>featherlite ladies moisture free mesh sport sh...</td>\n",
       "      <td>$20.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>B014ICEJ1Q</td>\n",
       "      <td>FNC7C</td>\n",
       "      <td>Purple</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>supernatural chibis sam dean castiel neck tshi...</td>\n",
       "      <td>$7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>B01NACPBG2</td>\n",
       "      <td>Fifth Degree</td>\n",
       "      <td>Black</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>SHIRT</td>\n",
       "      <td>fifth degree womens gold foil graphic tees jun...</td>\n",
       "      <td>$6.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          asin                        brand              color  \\\n",
       "4   B004GSI2OS                  FeatherLite  Onyx Black/ Stone   \n",
       "6   B012YX2ZPI  HX-Kingdom Fashion T-shirts              White   \n",
       "15  B003BSRPB0                  FeatherLite              White   \n",
       "27  B014ICEJ1Q                        FNC7C             Purple   \n",
       "46  B01NACPBG2                 Fifth Degree              Black   \n",
       "\n",
       "                                     medium_image_url product_type_name  \\\n",
       "4   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "6   https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "15  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "27  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "46  https://images-na.ssl-images-amazon.com/images...             SHIRT   \n",
       "\n",
       "                                                title formatted_price  \n",
       "4   featherlite ladies long sleeve stain resistant...          $26.26  \n",
       "6   womens unique 100 cotton  special olympics wor...           $9.99  \n",
       "15  featherlite ladies moisture free mesh sport sh...          $20.54  \n",
       "27  supernatural chibis sam dean castiel neck tshi...           $7.39  \n",
       "46  fifth degree womens gold foil graphic tees jun...           $6.95  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('16k_apperal_data_preprocessed')\n",
    "data.head()\n",
    "#directly getting the data from the pickle-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions which we will use through the rest of the workshop.\n",
    "\n",
    "\n",
    "#Display an image\n",
    "def display_img(url,ax,fig):\n",
    "    # we get the url of the apparel and download it\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    # we will display it in notebook \n",
    "    plt.imshow(img)\n",
    "  \n",
    "#ploting code to understand the algorithm's decision.\n",
    "def plot_heatmap(keys, values, labels, url, text):\n",
    "        gs = gridspec.GridSpec(2, 2, width_ratios=[4,1], height_ratios=[4,1]) \n",
    "        fig = plt.figure(figsize=(25,3))\n",
    "        ax = plt.subplot(gs[0])\n",
    "        # it displays a cell in white color if the word is intersection(lis of words of title1 and list of words of title2), in black if not\n",
    "        ax = sns.heatmap(np.array([values]), annot=np.array([labels]))\n",
    "        ax.set_xticklabels(keys) # set that axis labels as the words of title\n",
    "        ax.set_title(text) # apparel title\n",
    "        \n",
    "        # 2nd, plotting image of the the apparel\n",
    "        ax = plt.subplot(gs[1])\n",
    "        # we don't want any grid lines for image and no labels on x-axis and y-axis\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        # we call dispaly_img based with paramete url\n",
    "        display_img(url, ax, fig)\n",
    "        \n",
    "        # displays combine figure ( heat map and image together)\n",
    "        plt.show()\n",
    "    \n",
    "def text_to_vector(text):\n",
    "    word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    # words stores list of all words in given string, you can try 'words = text.split()' this will also gives same result\n",
    "    return Counter(words) # Counter counts the occurence of each word in list, it returns dict type object {word1:count}\n",
    "\n",
    "\n",
    "\n",
    "def get_result(doc_id, content_a, content_b, url, model):\n",
    "    text1 = content_a\n",
    "    text2 = content_b\n",
    "    \n",
    "    # vector1 = dict{word11:#count, word12:#count, etc.}\n",
    "    vector1 = text_to_vector(text1)\n",
    "\n",
    "    # vector1 = dict{word21:#count, word22:#count, etc.}\n",
    "    vector2 = text_to_vector(text2)\n",
    "\n",
    "    plot_heatmap_image(doc_id, vector1, vector2, url, text2, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the IDF-Weighted Word2Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "with open('word2vec_model', 'rb') as handle:\n",
    "    model = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = model.keys()\n",
    "def build_avg_vec(sentence, num_features, doc_id, m_name):\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        nwords += 1\n",
    "        if word in vocab:\n",
    "            if m_name == 'weighted' and word in  idf_title_vectorizer.vocabulary_:\n",
    "                featureVec = np.add(featureVec, idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[word]] * model[word])\n",
    "            elif m_name == 'avg':\n",
    "                featureVec = np.add(featureVec, model[word])\n",
    "    if(nwords>0):\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_title_vectorizer = CountVectorizer()\n",
    "idf_title_features = idf_title_vectorizer.fit_transform(data['title'])\n",
    "def n_containing(word):\n",
    "    return sum(1 for blob in data['title'] if word in blob.split())\n",
    "\n",
    "def idf(word):\n",
    "    return math.log(data.shape[0] / (n_containing(word)))\n",
    "idf_title_features  = idf_title_features.astype(np.float)\n",
    "\n",
    "for i in idf_title_vectorizer.vocabulary_.keys():\n",
    "    idf_val = idf(i)\n",
    "    for j in idf_title_features[:, idf_title_vectorizer.vocabulary_[i]].nonzero()[0]:\n",
    "        idf_title_features[j,idf_title_vectorizer.vocabulary_[i]] = idf_val\n",
    "\n",
    "doc_id = 0\n",
    "w2v_title_weight = []\n",
    "for i in data['title']:\n",
    "    w2v_title_weight.append(build_avg_vec(i, 300, doc_id,'weighted'))\n",
    "    doc_id += 1\n",
    "# w2v_title = np.array(# number of doc in courpus * 300), each row corresponds to a doc \n",
    "w2v_title_weight = np.array(w2v_title_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Image Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the features and corresponding ASINS info.\n",
    "bottleneck_features_train = np.load('16k_data_cnn_features.npy')\n",
    "asins = np.load('16k_data_cnn_feature_asins.npy')\n",
    "asins = list(asins)\n",
    "\n",
    "# load the original 16K dataset\n",
    "data = pd.read_pickle('16k_apperal_data_preprocessed')\n",
    "df_asins = list(data['asin'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combining the image,text-IDF W2V,Brands,Types,colors features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the brand values are empty. \n",
    "# Need to replace Null with string \"NULL\"\n",
    "data['brand'].fillna(value=\"Not given\", inplace=True )\n",
    "\n",
    "# replace spaces with hypen\n",
    "brands = [x.replace(\" \", \"-\") for x in data['brand'].values]\n",
    "colors = [x.replace(\" \", \"-\") for x in data['color'].values]\n",
    "\n",
    "brand_vectorizer = CountVectorizer()\n",
    "brand_features = brand_vectorizer.fit_transform(brands)\n",
    "\n",
    "type_vectorizer = CountVectorizer()\n",
    "type_features = type_vectorizer.fit_transform(types)\n",
    "\n",
    "color_vectorizer = CountVectorizer()\n",
    "color_features = color_vectorizer.fit_transform(colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = hstack((brand_features , color_features, bottleneck_features_train, w2v_title_weight)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN : B00JXQB5FQ\n",
      "Brand : Si Row\n",
      "=========================\n",
      "euclidean distance from input : 5.9081768035888675\n",
      "=============================================================================================================================\n",
      "ASIN : B06XBHNM7J\n",
      "Brand : Xhilaration\n",
      "=========================\n",
      "euclidean distance from input : 25.01262226200123\n",
      "=============================================================================================================================\n",
      "ASIN : B018H5AZXQ\n",
      "Brand : Buffalo\n",
      "=========================\n",
      "euclidean distance from input : 25.64025949557538\n",
      "=============================================================================================================================\n",
      "ASIN : B01L7ROZNC\n",
      "Brand : Bila\n",
      "=========================\n",
      "euclidean distance from input : 26.086720322524876\n",
      "=============================================================================================================================\n",
      "ASIN : B06XYP1X1F\n",
      "Brand : J Brand Jeans\n",
      "=========================\n",
      "euclidean distance from input : 26.129055005673354\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def idf_w2v_brand(doc_id, w1, w2, w3, num_results):\n",
    "    # doc_id: apparel's id in given corpus\n",
    "    # w1: weight for  w2v features\n",
    "    # w2: weight for brand and color features\n",
    "    #w3: weight for image features\n",
    "    # pairwise_dist will store the distance from given input apparel to all remaining apparels\n",
    "    # the metric we used here is cosine, the coside distance is mesured as K(X, Y) = <X, Y> / (||X||*||Y||)\n",
    "    # http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity\n",
    "    idf_w2v_dist  = pairwise_distances(w2v_title_weight, w2v_title_weight[doc_id].reshape(1,-1))\n",
    "    ex_feat_dist = pairwise_distances(extra_features, extra_features[doc_id])\n",
    "    doc_id = asins.index(df_asins[doc_id])\n",
    "    pairwise = pairwise_distances(bottleneck_features_train, bottleneck_features_train[doc_id].reshape(1,-1))\n",
    "#calculating the distance of the input with weights\n",
    "    pairwise_dist   = (w1 * idf_w2v_dist +  w2 * ex_feat_dist + w3 *pairwise)/float(w1 + w2 + w3)\n",
    "\n",
    "    # np.argsort will return indices of 9 smallest distances\n",
    "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
    "    #pdists will store the 9 smallest distances\n",
    "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
    "\n",
    "    #data frame indices of the 9 smallest distace's\n",
    "    df_indices = list(data.index[indices])\n",
    "    \n",
    "\n",
    "    for i in range(0, len(indices)):\n",
    "        print('ASIN :',data['asin'].loc[df_indices[i]])\n",
    "        print('Brand :',data['brand'].loc[df_indices[i]])\n",
    "        print('='*25)\n",
    "        print('euclidean distance from input :', pdists[i])\n",
    "        print('='*125)\n",
    "\n",
    "idf_w2v_brand(12566, 5, 4, 1, 5)\n",
    "# in the give heat map, each cell contains the euclidean distance between words i, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above we have used weights 5,4,1 in which the image feature is given low priority considering this let us different example of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN : B01M0IDUCV\n",
      "Brand : Premise\n",
      "=========================\n",
      "euclidean distance from input : 10.622462092472018\n",
      "=============================================================================================================================\n",
      "ASIN : B01N4NQ7LX\n",
      "Brand : CeCe by Cynthia Steffe\n",
      "=========================\n",
      "euclidean distance from input : 32.855989093712736\n",
      "=============================================================================================================================\n",
      "ASIN : B01IU645VU\n",
      "Brand : Outback Red\n",
      "=========================\n",
      "euclidean distance from input : 41.36311345463786\n",
      "=============================================================================================================================\n",
      "ASIN : B01FQLKKMK\n",
      "Brand : SLJD\n",
      "=========================\n",
      "euclidean distance from input : 43.72992446095258\n",
      "=============================================================================================================================\n",
      "ASIN : B00JXQB5FQ\n",
      "Brand : Si Row\n",
      "=========================\n",
      "euclidean distance from input : 44.29700215657552\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "idf_w2v_brand(12566, 1, 2, 9, 5)\n",
    "#taking more weight towards image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN : B00JXQB5FQ\n",
      "Brand : Si Row\n",
      "=========================\n",
      "euclidean distance from input : 8.438020433698382\n",
      "=============================================================================================================================\n",
      "ASIN : B06XBHNM7J\n",
      "Brand : Xhilaration\n",
      "=========================\n",
      "euclidean distance from input : 36.643294336114955\n",
      "=============================================================================================================================\n",
      "ASIN : B018H5AZXQ\n",
      "Brand : Buffalo\n",
      "=========================\n",
      "euclidean distance from input : 38.1491945485259\n",
      "=============================================================================================================================\n",
      "ASIN : B074MXY984\n",
      "Brand : We The Free\n",
      "=========================\n",
      "euclidean distance from input : 38.415151996427255\n",
      "=============================================================================================================================\n",
      "ASIN : B06XYP1X1F\n",
      "Brand : J Brand Jeans\n",
      "=========================\n",
      "euclidean distance from input : 38.47830605784304\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "idf_w2v_brand(12566, 1, 5, 1, 5)\n",
    "#taking more weight towards brand-color features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "- using weighted distances enables us to consider which feature would be more important based on the business requirements.\n",
    "- There is a huge difference with the usage of different weights as we can see in the above results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
